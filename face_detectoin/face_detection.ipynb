{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9bee74",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6973f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e3faf",
   "metadata": {},
   "source": [
    "### Download model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f5542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"deploy.prototxt\"):\n",
    "    print(\"Downloading deploy.prototxt...\")\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\",\n",
    "        \"deploy.prototxt\",\n",
    "    )\n",
    "\n",
    "if not os.path.exists(\"res10_300x300_ssd_iter_140000.caffemodel\"):\n",
    "    print(\"Downloading model weights...\")\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\",\n",
    "        \"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "    )\n",
    "\n",
    "# Load the pre-trained Caffe model\n",
    "try:\n",
    "    net = cv2.dnn.readNetFromCaffe(\n",
    "        \"deploy.prototxt\", \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error loading model:\", e)\n",
    "    raise SystemExit(\"Failed to load face detection model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab56e3c",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac5bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img, confidence_threshold=0.5):  # Lower confidence threshold\n",
    "    (h, w) = img.shape[:2]\n",
    "\n",
    "    # Create blob with larger scale to detect smaller faces\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        cv2.resize(img, (500, 500)),  # Input size\n",
    "        1.0,  # Scale factor\n",
    "        (500, 500),  # Spatial size\n",
    "        (104.0, 177.0, 123.0),  # Mean subtraction (BGR)\n",
    "        swapRB=False,  # Swap Red/Blue\n",
    "        crop=False,  # Center crop\n",
    "    )\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    faces = []\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > confidence_threshold:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Ensure coordinates are within image bounds\n",
    "            startX = max(0, startX)\n",
    "            startY = max(0, startY)\n",
    "            endX = min(w, endX)\n",
    "            endY = min(h, endY)\n",
    "\n",
    "            # Only add if face is reasonably sized\n",
    "            face_width = endX - startX\n",
    "            face_height = endY - startY\n",
    "            if face_width > 20 and face_height > 20:  # Minimum face size\n",
    "                faces.append([startX, startY, face_width, face_height])\n",
    "\n",
    "    # Less aggressive NMS for crowded images\n",
    "    return non_max_suppression(np.array(faces), overlapThresh=0.3)\n",
    "\n",
    "\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    # Remove duplicate detections of the same face\n",
    "    # Reduce false positives in crowded scenes\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 0] + boxes[:, 2]\n",
    "    y2 = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(\n",
    "            idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0]))\n",
    "        )\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None, 0\n",
    "\n",
    "    # Convert to RGB (better for face detection)\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = detect_faces(rgb_img)\n",
    "\n",
    "    # Draw rectangles on original BGR image\n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return img, len(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7da079",
   "metadata": {},
   "source": [
    "### Process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f612d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (1).jpg: Detected 1 faces\n",
      "data (10).jpg: Detected 4 faces\n",
      "data (11).jpg: Detected 6 faces\n",
      "data (12).jpg: Detected 7 faces\n",
      "data (2).jpg: Detected 7 faces\n",
      "data (3).jpg: Detected 15 faces\n",
      "data (4).jpg: Detected 3 faces\n",
      "data (5).jpg: Detected 5 faces\n",
      "data (6).jpg: Detected 4 faces\n",
      "data (7).jpg: Detected 1 faces\n",
      "data (8).jpg: Detected 1 faces\n",
      "data (9).jpg: Detected 7 faces\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "os.makedirs(\"output_images\", exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(\"dataset\"):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(\"dataset\", filename)\n",
    "        processed_img, face_count = process_image(img_path)\n",
    "\n",
    "        if processed_img is not None:\n",
    "            output_path = os.path.join(\"output_images\", f\"detected_{filename}\")\n",
    "            cv2.imwrite(output_path, processed_img)\n",
    "            print(f\"{filename}: Detected {face_count} faces\")  # Correct count\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
